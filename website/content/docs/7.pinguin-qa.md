---
title: "Pinguin QA : Recherche Vectorielle Ultra-Rapide"
description: "Système de questions-réponses basé sur FAISS et Sentence Transformers pour les transcriptions vocales."
category: "Lab"
tags: ["QA", "NLP", "Pinguin", "Voice"]
---

# Pinguin QA : Recherche Vectorielle Ultra-Rapide

Le système **Pinguin QA** est un module conçu pour interroger instantanément les transcriptions vocales générées par le module Kyutai. Il utilise des techniques de recherche sémantique pour trouver des réponses précises dans le flux de texte, même avec des questions formulées différemment des paroles exactes.

## Architecture Technique

Le système repose sur deux piliers principaux :

1.  **Sentence Transformers** : Utilise le modèle `paraphrase-multilingual-MiniLM-L12-v2` pour transformer le texte en vecteurs mathématiques (embeddings).
2.  **FAISS (Facebook AI Similarity Search)** : Une bibliothèque optimisée pour la recherche de similarité vectorielle ultra-rapide.

### Performances

- **Temps de réponse** : ~50-200ms par requête sur CPU.
- **Précision** : Recherche sémantique (comprend le sens, pas seulement les mots-clés).
- **Léger** : Faible empreinte mémoire pour une utilisation sur des serveurs légers.

---

## Fonctionnement du module

### 1. Découpage Contextuel
La transcription est intelligemment découpée en segments avec une fenêtre de contexte ajustable. Cela permet à l'IA de comprendre le "n-1" et "n+1" d'une phrase pour donner une réponse plus complète.

### 2. Indexation FAISS
Les segments sont encodés et injectés dans un index FAISS `IndexFlatIP`. La similarité cosinus (via Inner Product sur vecteurs normalisés) est utilisée pour classer les résultats.

### 3. Formatage de Réponse Naturelle
Le système ne se contente pas de renvoyer le texte brut ; il ajoute une couche de "naturalité" en fonction du score de confiance :
- **Confiance > 80%** : "Ah oui ! [Texte]"
- **Confiance > 50%** : "D'après ce que j'ai : [Texte]"
- **Confiance faible** : "Je pense que : [Texte]"

---

## Implémentation Core

```python
class FastQASystem:
    def __init__(self, model_name='paraphrase-multilingual-MiniLM-L12-v2'):
        self.model = SentenceTransformer(model_name)
        self.index = None
        self.segments = []

    def index_transcription(self, transcription, window_size=1):
        # Découpage et encodage
        self.segments = self.prepare_transcription(transcription, window_size)
        embeddings = self.model.encode(self.segments, convert_to_numpy=True)
        
        # Création de l'index FAISS
        dimension = embeddings.shape[1]
        self.index = faiss.IndexFlatIP(dimension)
        faiss.normalize_L2(embeddings)
        self.index.add(embeddings)

    def answer(self, question):
        results = self.search(question, top_k=1)
        # Logic de formatage...
        return result
```

---

## Intégration dans l'écosystème Pinguin

Ce module complète la chaîne de traitement audio de Pinguin :
1. **Pinguin Audio** (iOS) : Capture l'audio.
2. **Kyutai STT** (Serveur) : Transcrit l'audio en texte.
3. **Pinguin QA** (Serveur) : Permet d'interroger la mémoire de la conversation.

> [!TIP]
> Pour une utilisation en production, l'index FAISS peut être sauvegardé sur disque pour éviter de ré-encoder toute la transcription à chaque redémarrage si celle-ci est persistante.

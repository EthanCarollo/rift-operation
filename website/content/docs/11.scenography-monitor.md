---
title: Scenography Monitor
description: Documentation du Scenography Monitor, un logiciel de pilotage audio par WebSocket.
---

# Scenography Monitor

Le **Scenography Monitor** est un logiciel conçu pour piloter la scénographie sonore de manière dynamique via des messages WebSocket.

L'objectif principal est de permettre un déclenchement réactif des ambiances sonores et des bruitages en fonction de l'état du système (IoT, interactions utilisateur, scénario), sans dépendre d'une timeline linéaire fixe.

## Philosophie : "FL Studio Event-Driven"

L'architecture du logiciel s'inspire directement des stations de travail audio numériques (DAW) comme **FL Studio**, notamment dans sa gestion des samples et du mixage, mais avec une différence fondamentale :

*   **FL Studio** : Utilise une **Timeline** (axe temporel) pour séquencer les sons.
*   **Scenography Monitor** : Utilise les **Messages WebSocket** pour déclencher les sons.

Il n'y a pas de bouton "Play" global ni de curseur de temps. Le système est en attente passive d'événements réseaux qui agissent comme des "déclencheurs" (Triggers).

## Principe de Fonctionnement

Le workflow se décompose en trois liaisons (bindings) essentielles :

### 1. Audio → Bus (Rack)
Les fichiers audio (wav, mp3, m4a) importés dans la bibliothèque ne sont pas joués directement. Ils doivent être assignés à des **Bus** (ou Pistes).
*   On crée une **Instance** d'un son sur un Bus spécifique.
*   Un même son peut être instancié plusieurs fois sur des Bus différents (ou le même) avec des paramètres différents.

### 2. Bus → Sorties Audio (Hardware)
Chaque **Bus** (1 à 12) possède sa propre configuration de routage.
*   Ils peuvent être assignés à n'importe quelle sortie audio physique détectée par le Mac (ex: *Casque*, *Enceintes Studio*, *HDMI*, *Virtuel*).
*   Cela permet de spatialiser le son physiquement (ex: envoyer la voix de l'IA dans un haut-parleur spécifique et l'ambiance musicale dans un autre).

### 3. WebSocket → Instances (Binding)
C'est le cœur du système. On crée des **Bindings** (Liaisons) entre un message WebSocket et une instance de son.
*   **Source** : Une clé et une valeur JSON (ex: `{ "stranger_state": "active" }`).
*   **Action** : Jouer l'instance du son "tension_bg.wav" située sur le Bus 1.

## Architecture Technique

Le système repose sur plusieurs composants clés :

*   **Sound Library** : Gestionnaire de fichiers, scanne le dossier de sons.
*   **Audio Engine** : Moteur audio basse latence capable de gérer plusieurs périphériques de sortie simultanément (une instance `AVAudioEngine` par périphérique physique).
*   **WebSocket Manager** : Écoute le flux temps réel provenant du serveur central.
*   **Sound Trigger** : Compare les messages entrants avec la liste des Bindings et déclenche les lectures.

## Exemple de Flux

1.  **Configuration** :
    *   L'utilisateur place le son `bruit_pas.wav` sur le **Bus 2**.
    *   Le **Bus 2** est routé vers la sortie `Enceinte Arrière`.
    *   Un Binding est créé : Si `sensor_floor` = `triggered`, alors jouer `bruit_pas.wav` (Bus 2).

2.  **Exécution** :
    *   Un capteur IoT détecte un mouvement.
    *   Le serveur envoie le message WebSocket : `{ "sensor_floor": "triggered" }`.
    *   Le Scenography Monitor reçoit le message.
    *   Il identifie le Binding correspondant.
    *   Il joue le son instantanément sur l'enceinte arrière.
